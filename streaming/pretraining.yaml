base_model: HuggingFaceTB/SmolLM2-135M
pretraining_dataset:
  - path: mhenrichsen/alpaca_2k_test
    type: alpaca

# Streaming config
streaming: true
max_steps: 1000

# Dataset mixing with round-robin strategy (alternating samples)
# dataset_mixing_strategy: round_robin

gradient_accumulation_steps: 1
learning_rate: 1e-4
micro_batch_size: 1
sequence_len: 4096
special_tokens:
  pad_token: <|endoftext|>
flash_attention: true
sample_packing: true

# wandb_project: streaming
# wandb_entity: axolotl-ai
# wandb_watch: all
# wandb_name:
# wandb_log_model: end

random_init_weights: true
