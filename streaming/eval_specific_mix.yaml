base_model: HuggingFaceTB/SmolLM2-135M
datasets:
  - path: mhenrichsen/alpaca_2k_test
    type: alpaca
  - path: tatsu-lab/alpaca
    type: alpaca

test_datasets:
  - path: mhenrichsen/alpaca_2k_test
    type: alpaca
    split: train
  - path: tatsu-lab/alpaca
    type: alpaca
    split: train

# Streaming config
streaming: true
eval_streaming: true
max_steps: 1000

# Different mixing strategies for train vs eval
dataset_mixing_strategy: round_robin
eval_dataset_mixing_strategy: weighted
eval_mixing_weights: [0.6, 0.4]

gradient_accumulation_steps: 1
learning_rate: 1e-5
micro_batch_size: 1
sequence_len: 1024
special_tokens:
  pad_token: <|endoftext|>
flash_attention: true
# sample_packing: false
sample_packing: true
