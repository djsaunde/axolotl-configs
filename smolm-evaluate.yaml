base_model: HuggingFaceTB/SmolLM2-135M
datasets:
  - path: mhenrichsen/alpaca_2k_test
    type: alpaca
test_datasets:
  - path: mhenrichsen/alpaca_2k_test
    type: alpaca
    split: train
# sdp_attention: true
gradient_accumulation_steps: 1
# learning_rate: 1e-4
# max_steps: 1000
micro_batch_size: 1
sequence_len: 2048
special_tokens:
  pad_token: <|endoftext|>

# wandb_project: diff-transformer
# wandb_entity: axolotl-ai
# wandb_watch: all
# wandb_name: base-smollm2-135m
# wandb_log_model:  q