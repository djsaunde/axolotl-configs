base_model: HuggingFaceTB/SmolLM2-135M
datasets:
  - path: mhenrichsen/alpaca_2k_test
    type: alpaca

gradient_accumulation_steps: 1
learning_rate: 1e-4
val_set_size: 0.1
micro_batch_size: 1
sequence_len: 4096
special_tokens:
  pad_token: <|endoftext|>
flash_attention: true
sample_packing: false

deepspeed: deepspeed_configs/zero3_bf16.json
